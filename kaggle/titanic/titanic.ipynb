{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kaggle Titanic Competition - could Jack have lived?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Set and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read into our datasets\n",
    "dataset = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "submission = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Feature Engineering\n",
    "\n",
    "In this section, we'll explore some basic structure of our data and try to come up creative ways of reformatting our features to make it more machine readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Structure Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender (Sex)\n",
    "Now that you have a rough understanding of what each feature entail. Let's first start by exploring how gender is related to the overall survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.Sex = dataset.Sex.apply(lambda x: 1 if x == 'female' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_sex = dataset[['Sex', 'Survived']].groupby('Sex').sum()\n",
    "survived_by_sex['People'] = dataset.groupby('Sex').count().Survived\n",
    "survived_by_sex['PctSurvived'] = survived_by_sex.Survived / survived_by_sex.People\n",
    "survived_by_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_sex[['Survived', 'People']].plot(kind='bar', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passenger Class (Pclass)\n",
    "\n",
    "What about survivial with respect to each passenger class (Pclass)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_pclass = dataset[['Pclass', 'Survived']].groupby('Pclass').sum()\n",
    "survived_by_pclass['People'] = dataset.groupby('Pclass').count().Survived\n",
    "survived_by_pclass['PctSurvived'] = survived_by_pclass.Survived / survived_by_pclass.People\n",
    "survived_by_pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_pclass[['Survived', 'People']].plot(kind='bar', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about if we separated social class and gender, how does our survival rate look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_pclass_sex = dataset.groupby(['Sex', 'Pclass']) \\\n",
    "    .apply(lambda x: x.Survived.sum() / len(x)) \\\n",
    "    .unstack()\n",
    "\n",
    "survived_by_pclass_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_pclass_sex.plot(kind='bar', title='Pct Survived by Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Port of Embarkment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_embarked = dataset[['Embarked', 'Survived']].groupby('Embarked').sum()\n",
    "survived_by_embarked['People'] = dataset[['Embarked', 'Survived']].groupby('Embarked').count()\n",
    "survived_by_embarked['PctSurvived'] = survived_by_embarked.Survived/survived_by_embarked.People\n",
    "\n",
    "survived_by_embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_embarked[['Survived', 'People']].plot(kind='bar', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['AgeGroup'] = dataset.Age.dropna().apply(lambda x: int(x/5)*5)\n",
    "dataset['AgeGroup1'] = dataset.Age.dropna().apply(lambda x: int(x/1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = dataset.Age.hist(bins=len(dataset.AgeGroup.unique()))\n",
    "dataset[['Sex', 'AgeGroup', 'Name']].groupby(['AgeGroup', 'Sex']).count().unstack('Sex').plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_agegroup = dataset[['AgeGroup', 'Survived']].groupby('AgeGroup').sum()\n",
    "survived_by_agegroup['People'] = dataset[['AgeGroup', 'Survived']].groupby('AgeGroup').count()\n",
    "survived_by_agegroup['PctSurvived'] = survived_by_agegroup.Survived/survived_by_agegroup.People\n",
    "\n",
    "survived_by_agegroup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survived_by_agegroup[['Survived', 'People']].plot(kind='bar', figsize=(16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_agegroup1 = dataset[['AgeGroup1', 'Survived']].groupby('AgeGroup1').sum()\n",
    "survived_by_agegroup1['People'] = dataset[['AgeGroup1', 'Survived']].groupby('AgeGroup1').count()\n",
    "survived_by_agegroup1['PctSurvived'] = survived_by_agegroup1.Survived/survived_by_agegroup.People\n",
    "\n",
    "survived_by_agegroup1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survived_by_agegroup1[['Survived', 'People']].plot(kind='bar', figsize=(16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_age = dataset[dataset.Age <= 60][['Age', 'Survived']].sort_values('Age')\n",
    "survived_by_age['CumSurvived'] = survived_by_age.Survived.cumsum()\n",
    "survived_by_age['CumCount'] = [x+1 for x in range(len(survived_by_age))]\n",
    "survived_by_age['CumSurvivalRate'] = survived_by_age.CumSurvived / survived_by_age.CumCount\n",
    "\n",
    "survived_by_age.plot(kind='scatter', x='Age', y='CumSurvivalRate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_age[(survived_by_age.Age >= 5) & (survived_by_age.Age <= 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.Fare.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[['Pclass', 'Fare']].groupby('Pclass').describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fare_pclass_mean = dataset[['Pclass', 'Fare']][dataset.Fare > 1].groupby('Pclass').mean()\n",
    "fare_pclass_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.Fare = dataset.apply(lambda x: fare_pclass_mean.loc[x.Pclass][0] if x.Fare < 1 else x.Fare, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.boxplot(data=dataset, x='Pclass', y='Fare', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there's a relationshp between fare price and those who has survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[['Pclass', 'Fare']][dataset.Survived == 1].groupby('Pclass').describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[['Pclass', 'Fare']][dataset.Survived == 0].groupby('Pclass').describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset[dataset.Survived == 1], x='Pclass', y='Fare')\n",
    "plt.title(\"Survivor's Fare Price by Pclass\")\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(data=dataset[dataset.Survived == 0], x='Pclass', y='Fare')\n",
    "plt.title(\"Non-Survivor's Fare Price by Pclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of people surivived by pclass\n",
    "\n",
    "And not surpringly, people in better passenger classes had higher surivival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_fare_pclass = dataset[['Fare', 'Survived', 'Pclass']].groupby(['Pclass', 'Survived']).mean().unstack('Survived')\n",
    "survived_by_fare_pclass.plot(kind='bar', rot=0)\n",
    "plt.title('Survived by Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define cabin class\n",
    "dataset['CabinClass'] = dataset.Cabin.dropna().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cabinclass = dataset[['CabinClass', 'Survived']].groupby('CabinClass').sum()\n",
    "cabinclass['People'] = dataset.groupby('CabinClass').count().Survived\n",
    "cabinclass['PctSurvived'] = cabinclass.Survived / cabinclass.People\n",
    "cabinclass['AvgFare'] = dataset.groupby('CabinClass').mean().Fare\n",
    "cabinclass['AvgAge'] = dataset.groupby('CabinClass').mean().Age\n",
    "cabinclass['PctFemaleInCabin'] = dataset.groupby('CabinClass').apply(lambda x: len(x[x.Sex == 1]) / len(x))\n",
    "\n",
    "cabinclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cabinclass[['Survived', 'People']].plot(kind='bar', figsize=(16,8), title='Survived by Cabin Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, cabin_class in enumerate(dataset.CabinClass.unique()):\n",
    "    dataset.loc[dataset.CabinClass == cabin_class, 'CabinClass'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "cabin_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'PersonType', 'Mother']\n",
    "\n",
    "#clf_cabin = sklearn.linear_model.RidgeCV(alphas=[0.1,0.5,1,2,5])\n",
    "clf_cabin = sklearn.ensemble.RandomForestRegressor(n_estimators=500)\n",
    "\n",
    "clf_cabin.fit(dataset[cabin_features][~pd.isnull(dataset.CabinClass)], dataset[~pd.isnull(dataset.CabinClass)].CabinClass)\n",
    "\n",
    "#dataset['PredictedCabinClass'] = clf_cabin.predict(dataset[cabin_features])\n",
    "\n",
    "dataset[~pd.isnull(dataset.CabinClass)]['CabinClass'] = np.round(clf_cabin.predict(dataset[~pd.isnull(dataset.CabinClass)][cabin_features]))\n",
    "clf_cabin.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = dataset.CabinClass.hist()\n",
    "#dataset.PredictedCabinClass.hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataset.PredictedCabinClass.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataset.PredictedCabinClass.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.CabinClass.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.round(clf_cabin.predict(dataset[cabin_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Titles from Name\n",
    "\n",
    "And using the title and other features to predict our age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read into our datasets\n",
    "dataset = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "submission = pd.read_csv('test.csv')\n",
    "df_union = pd.concat([dataset, submission])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset[pd.isnull(dataset.Age)]\n",
    "#dataset.sort_values('Name').head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_union['Title'] = df_union.Name.apply(lambda x: (x.split(',')[1]).split('.')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_union[['Age','Title']].groupby('Title').describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_union[['Sex','Title','Survived']].groupby(['Title','Sex']).sum().unstack('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def title_mapping(x):\n",
    "    #if x in set(['Capt', 'Col', 'Don', 'Major', 'Rev', 'Sir', 'Jonkheer']):\n",
    "    if x in set(['Don', 'Rev', 'Sir', 'Jonkheer']):\n",
    "        return 'Mr'\n",
    "    elif x in set(['Lady', 'the Countess']):\n",
    "        return 'Mrs'\n",
    "    elif x in set(['Mlle', 'Mme', 'Dona', 'Ms']):\n",
    "        return \"Miss\"\n",
    "    elif x in set(['Major', 'Col', 'Capt']):\n",
    "        return \"Officer\"\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset['Title'] = df.Name.apply(lambda x: (x.split(',')[1]).split('.')[0][1:])\n",
    "dataset.Title = dataset.Title.apply(title_mapping)\n",
    "dataset.loc[(dataset.Sex == 1) & (dataset.Title == 'Dr'), 'Title'] = 'Mrs'\n",
    "dataset.loc[(dataset.Sex == 0) & (dataset.Title == 'Dr'), 'Title'] = 'Mr'\n",
    "\n",
    "dataset.Title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = { 'Master' : 0, 'Miss' : 1, 'Mr' : 2, 'Mrs': 4, 'Officer': 5}\n",
    "dataset.Title = dataset.Title.apply(lambda x: titles.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[['Age', 'Title']].groupby('Title').describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[dataset.Title == 2].Age.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset['Mother'] = dataset.apply(lambda x: (x.Sex == 1) & (x.Age >= 18) & (x.Parch > 0) & (x.Title == 4), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[dataset.Mother == 1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset['FamilyName'] = dataset.Name.apply(lambda x: x.split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[dataset.FamilyName.isin(dataset[(dataset.FamilySize > 1)].groupby('FamilyName').count().index)].sort_values('FamilyName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived_by_family_name = dataset[['Survived', 'FamilyName']].groupby('FamilyName').sum()\n",
    "# survived_by_family_name['FamilySize'] = dataset[['Survived', 'FamilyName']].groupby('FamilyName')\n",
    "\n",
    "\n",
    "survived_by_family_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning and Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read into our datasets\n",
    "dataset = pd.read_csv('train.csv')\n",
    "submission = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_data(df): \n",
    "    df_union = pd.concat([dataset, submission])\n",
    "    \n",
    "    # Map sex into 0 for male, 1 for female\n",
    "    # df.Sex = df.Sex.apply(lambda x: 0 if x == 'male' else 1)\n",
    "    # df.Sex = pd.Series(map(lambda x: x == 'female', df.Sex))\n",
    "    # df.Sex = df.Sex.map({'male':0, 'female':1})\n",
    "    def convert_sex(x):\n",
    "        if x == 'male':\n",
    "            return 0\n",
    "        elif x == 'female':\n",
    "            return 1\n",
    "        else:\n",
    "            return x\n",
    "    df.Sex = df.Sex.apply(convert_sex)\n",
    "    \n",
    "    # Map embarked location into numbers after filling missing embark as the most common location\n",
    "    # embarked = {'S':1, 'C':2, 'Q':3}\n",
    "    embarked = { name : i for i, name in enumerate(df_union.Embarked.unique())}\n",
    "    df.Embarked.fillna(df_union.Embarked.mode()[0], inplace=True)\n",
    "    df.Embarked = df.Embarked.apply(lambda x: embarked.get(x))\n",
    "    \n",
    "    # Fill missing fare with the median of its pclass\n",
    "    pclass_median = df_union[['Pclass', 'Fare']].groupby('Pclass').median()\n",
    "    for pclass in df_union.Pclass.unique():\n",
    "        #df.Fare[df.Pclass == pclass].fillna(pclass_median.loc[pclass], inplace=True)\n",
    "        df.loc[(df.Pclass == pclass) & (df.Fare.isnull()), 'Fare'] = pclass_median.loc[pclass][0]\n",
    "    \n",
    "    # Normalize Pclass to start at 0\n",
    "    df.Pclass = df.Pclass - 1\n",
    "    \n",
    "    # Family Size\n",
    "    df['FamilySize'] = df.SibSp + df.Parch + 1\n",
    "    \n",
    "    # Fill in missing fare prices\n",
    "    fare_pclass_mean = dataset[['Pclass', 'Fare']][dataset.Fare > 1].groupby('Pclass').mean()\n",
    "    df.Fare = df.apply(lambda x: fare_pclass_mean.loc[x.Pclass][0] if x.Fare < 1 else x.Fare, axis=1)\n",
    "    \n",
    "    # Create our newly engineered Title feature\n",
    "    df['Title'] = df.Name.apply(lambda x: (x.split(',')[1]).split('.')[0][1:])\n",
    "    df.Title = df.Title.apply(title_mapping)\n",
    "    df.loc[(df.Sex == 1) & (df.Title == 'Dr'), 'Title'] = 'Mrs'\n",
    "    df.loc[(df.Sex == 0) & (df.Title == 'Dr'), 'Title'] = 'Mr'\n",
    "    \n",
    "    #titles = { name : i for i, name in enumerate(df.Title.unique())}\n",
    "    titles = { 'Master' : 0, 'Miss' : 1, 'Mr' : 2, 'Mrs': 4, 'Officer': 5}\n",
    "    df.Title = df.Title.apply(lambda x: titles.get(x))\n",
    "    \n",
    "    # Cabin \n",
    "    df['CabinClass'] = df.Cabin.dropna().str[0]\n",
    "    for i, cabin_class in enumerate(df.CabinClass.unique()):\n",
    "        df.loc[df.CabinClass == cabin_class, 'CabinClass'] = i\n",
    "    \n",
    "    \n",
    "def fill_age(df):\n",
    "    df_union = pd.concat([dataset, submission])\n",
    "    if False:\n",
    "        clf_ridge = sklearn.linear_model.RidgeCV(alphas=[0.1,0.5,1,3,5])\n",
    "        age_features = ['Sex', 'SibSp', 'Parch', 'Fare', 'Title']\n",
    "        clf_ridge.fit(df_union[~pd.isnull(df_union.Age)][age_features], df_union[~pd.isnull(df_union.Age)].Age)\n",
    "\n",
    "        #df['PredictedAge'] = df.Age\n",
    "        df['PredictedAge'] = clf_ridge.predict(df[age_features])\n",
    "        #df.loc[pd.isnull(df.Age), 'Age'] = clf_ridge.predict(df[pd.isnull(df.Age)][age_features])\n",
    "\n",
    "    #df.Age.fillna(df_union.Age.median(), inplace=True)\n",
    "    \n",
    "    title_mean_age = df_union.groupby('Title').mean().Age\n",
    "    df.loc[pd.isnull(df.Age), 'Age'] = df[pd.isnull(df.Age)][['Age', 'Title']].apply(lambda x: title_mean_age[x.Title], axis=1)\n",
    "    \n",
    "    # Replace Sex with PersonType, which classifies Child\n",
    "    df['PersonType'] = df.Sex\n",
    "    df.loc[df.Age <= 18, 'PersonType'] = 3 # For youth\n",
    "    df.loc[df.Age <= 6, 'PersonType'] = 4 # For child\n",
    "    \n",
    "    # Find mothers\n",
    "    df['Mother'] = df.apply(lambda x: 1 if (x.Sex == 1) & (x.Age >= 18) & (x.Parch > 0) & (x.Title == 4) else 0, axis=1)\n",
    "\n",
    "def fill_cabin(df):\n",
    "    df_union = pd.concat([dataset, submission])\n",
    "    # Cabin \n",
    "    cabin_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'Mother', 'PersonType']\n",
    "    clf_cabin = sklearn.ensemble.RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "    clf_cabin.fit(df_union[cabin_features][~pd.isnull(df_union.CabinClass)], df_union[~pd.isnull(df_union.CabinClass)].CabinClass)\n",
    "\n",
    "    df.loc[pd.isnull(df.CabinClass), 'CabinClass'] = np.round(clf_cabin.predict(df[pd.isnull(df.CabinClass)][cabin_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_data(dataset)\n",
    "clean_data(submission)\n",
    "fill_age(dataset)\n",
    "fill_age(submission)\n",
    "fill_cabin(dataset)\n",
    "fill_cabin(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def age_group_classification(x):\n",
    "    if x <= 10:\n",
    "        return 0\n",
    "    elif x <= 35:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "dataset['AgeGroup'] = dataset.Age.apply(age_group_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataset.head(30)\n",
    "\n",
    "df_union = pd.concat([dataset, submission])\n",
    "age_features = ['Sex', 'SibSp', 'Parch', 'Fare', 'Title', 'Pclass', 'Embarked']\n",
    "age_features = ['Title']\n",
    "\n",
    "clf_age = sklearn.linear_model.RidgeCV(alphas=[0.1, 0.5, 1, 3, 5, 10])\n",
    "#clf_age = sklearn.linear_model.LogisticRegression()\n",
    "clf_age = sklearn.ensemble.RandomForestRegressor(n_estimators=500)\n",
    "\n",
    "clf_age.fit(df_union[~pd.isnull(df_union.Age)][age_features], df_union[~pd.isnull(df_union.Age)].Age)\n",
    "\n",
    "ax = dataset.Age.hist(alpha=0.3, label=['Original'], bins=10)\n",
    "\n",
    "pd.DataFrame(clf_age.predict(df_union[age_features]), columns=['PredictedAge']) \\\n",
    "    .hist(alpha=0.3, label=['Predicted'], color='r', ax=ax)\n",
    "\n",
    "#dataset['AgeAfter'] = dataset.Age\n",
    "#dataset.loc[pd.isnull(dataset.Age), 'AgeAfter'] = dataset[pd.isnull(dataset.Age)][['Age', 'Title']].apply(lambda x: title_mean_age[x.Title], axis=1)\n",
    "\n",
    "#dataset.AgeWithPredicted.hist(alpha=0.4, ax=ax, bins=10)\n",
    "#dataset.AgeAfter.hist(alpha=0.4, ax=ax, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null entries in our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[x_features][pd.isnull(dataset[x_features]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_features = ['Pclass', 'Sex', 'PersonType', 'Age', 'FamilySize', 'Fare', 'Embarked', 'Title',\n",
    "              'SibSp', 'Parch', 'Mother', 'CabinClass']\n",
    "features = x_features.copy() + ['Survived']\n",
    "\n",
    "# Make sure that there are no Nan entries in our dataset\n",
    "print(\"Nan Entries (dataset, submission):\",\n",
    "      len(dataset[pd.isnull(dataset[x_features]).any(axis=1).values]),\n",
    "      len(submission[pd.isnull(submission[x_features]).any(axis=1).values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Base Line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dataset[dataset.Survived == 0]) / len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "itrain, itest = sklearn.cross_validation.train_test_split(range(dataset.shape[0]), train_size=.70)\n",
    "\n",
    "mask=np.ones(dataset.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)\n",
    "mask[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = dataset[mask]\n",
    "test = dataset[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_c = {'C':[0.005, 0.1,0.5,1,2,5]}\n",
    "params_n_estimators = {'n_estimators':[500,1000,2000,4000]}\n",
    "\n",
    "clfs = []\n",
    "\n",
    "#clfs.append(sklearn.grid_search.GridSearchCV(sklearn.linear_model.LogisticRegression(), params_c, cv=5, scoring='f1'))\n",
    "#clfs.append(sklearn.grid_search.GridSearchCV(sklearn.svm.SVC(), params_c, cv=5, n_jobs=4))\n",
    "clfs.append(sklearn.grid_search.GridSearchCV(sklearn.ensemble.RandomForestClassifier(), params_n_estimators, cv=5, n_jobs=4))\n",
    "#clfs.append(sklearn.grid_search.GridSearchCV(sklearn.ensemble.AdaBoostClassifier(), params_n_estimators, cv=5, n_jobs=4))\n",
    "#clfs.append(sklearn.naive_bayes.GaussianNB())\n",
    "\n",
    "for clf in clfs:\n",
    "    clf.fit(train[x_features], train.Survived)\n",
    "\n",
    "print('models fitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for clf in clfs: \n",
    "    if isinstance(clf, sklearn.grid_search.GridSearchCV):\n",
    "        print(clf.best_estimator_)\n",
    "        print(clf.best_params_)\n",
    "        print(clf.best_score_)\n",
    "        print(clf.grid_scores_)\n",
    "        print('\\n')\n",
    "    #elif isinstance(clf, sklearn.naive_bayes.GaussianNB):\n",
    "    else:\n",
    "        print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well have we trained against our own training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for clf in clfs:\n",
    "    y_train_pred = clf.predict(train[x_features])\n",
    "    print(type(clf.best_estimator_) if isinstance(clf, sklearn.grid_search.GridSearchCV) else type(clf))\n",
    "    print(sklearn.metrics.classification_report(y_train_pred, train.Survived))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our classifiers against our validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing against our own test data\n",
    "\n",
    "for clf in clfs: \n",
    "    print(clf.best_estimator_.__class__.__name__ if isinstance(clf, sklearn.grid_search.GridSearchCV) else clf.__class__.__name__)\n",
    "    y_test_pred = clf.predict(test[x_features])\n",
    "    print(sklearn.metrics.classification_report(y_test_pred, test.Survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for over and underfitting with a learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for clf in clfs:\n",
    "#    name = clf.best_estimator_.__class__.__name__ if isinstance(clf, sklearn.grid_search.GridSearchCV) else clf.__class__.__name__\n",
    "#    plot_learning_curve(clf, name, train[x_features], train.Survived, train_sizes=np.linspace(0.3,1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for clf in clfs:\n",
    "    if isinstance(clf, sklearn.grid_search.GridSearchCV):\n",
    "        if isinstance(clf.best_estimator_, sklearn.ensemble.forest.RandomForestClassifier):\n",
    "            print('Random Forest:')\n",
    "            print(*zip(clf.best_estimator_.feature_importances_, x_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_submission = []\n",
    "for i, clf in enumerate(clfs):\n",
    "    # Retrain the best predictor with our entire test set\n",
    "    clf.best_estimator_.fit(dataset[x_features], dataset.Survived)\n",
    "    \n",
    "    final_submission.append(submission.copy())\n",
    "    final_submission[i]['Survived'] = pd.DataFrame(clf.predict(submission[x_features]))\n",
    "    name = clf.best_estimator_.__class__.__name__ if isinstance(clf, sklearn.grid_search.GridSearchCV) else clf.__class__.__name__\n",
    "    final_submission[i].to_csv('titanic_{}.csv'.format(name), columns=['PassengerId', 'Survived'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_submission[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logit_to_prob(x):\n",
    "    # equivalent to np.exp(x)/ (1+np.exp(x))\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_to_logit(x):\n",
    "    return np.log(x/(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(C=100000000)\n",
    "\n",
    "#new_train = train[pd.notnull(train.Age)]\n",
    "new_train = train\n",
    "features = ['Sex']\n",
    "\n",
    "clf.fit(new_train[features], new_train.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('log odds ratio:', np.sum(np.exp(clf.coef_)) + np.exp(clf.intercept_))\n",
    "\n",
    "print('base log odds ratio:', np.exp(clf.intercept_))\n",
    "print('female log odds ratio:',  clf.intercept_ + clf.coef_)\n",
    "print('probability of male surviving:', clf.intercept_, logit_to_prob(clf.intercept_))\n",
    "#print(\"increase in prob of survival if you're female\", clf.coef_, logit_to_prob(clf.coef_))\n",
    "print(np.exp(clf.coef_) - 1)\n",
    "\n",
    "print('probability of survival when female:', clf.intercept_ + clf.coef_, logit_to_prob(clf.intercept_ + clf.coef_))\n",
    "\n",
    "clf.intercept_, clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.coef_, np.exp(clf.coef_), logit_to_prob(clf.coef_ + clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sex = pd.DataFrame(train.Survived.groupby(train.Sex).sum())\n",
    "df_sex['Sex'] = train.Sex.groupby(train.Sex).count()\n",
    "df_sex['ProbOfSurvival'] = df_sex.Survived / df_sex.Sex\n",
    "df_sex['Logit(ProbOfSurvival)'] = prob_to_logit(df_sex.ProbOfSurvival)\n",
    "\n",
    "male_to_female_survival_odds = df_sex.iloc[0].ProbOfSurvival / df_sex.iloc[1].ProbOfSurvival\n",
    "print('Males to Female survival ratio: ', male_to_female_survival_odds)\n",
    "print('Log odds of Males to Female survival ratio: ', np.log(male_to_female_survival_odds))\n",
    "print(109/577)\n",
    "\n",
    "df_sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.coef_, np.exp(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sex.iloc[1].ProbOfSurvival / df_sex.iloc[0].ProbOfSurvival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.Survived[(train.Survived == 1) & (train.Sex == 1)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.742038/0.188908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_2 = ['Sex', 'Age', 'Fare', 'Survived']\n",
    "train_2 = train[features_2][pd.notnull(train.Sex) & pd.notnull(train.Age) & pd.notnull(train.Fare)]\n",
    "#Y_train_2 = train.Survived[pd.notnull(train.Sex) & pd.notnull(train.Age) & pd.notnull(train.Fare)]\n",
    "print(train_2.shape)\n",
    "train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_2 = sklearn.linear_model.LogisticRegression(C=1e10)\n",
    "clf_2.fit(train_2.drop('Survived', axis=1), train_2.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_2.intercept_, clf_2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.exp(clf_2.intercept_), np.exp(clf_2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "before = train_2[(train_2.Sex == 0) & (train_2.Fare <= 10) & (train_2.Age < 35)].groupby('Survived').count()\n",
    "before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "22/126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_2[(train_2.Sex == 0) & (train_2.Fare <= 10) & (train_2.Age < 36)].groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "22/131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(22/131)/(22/126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_2[(train_2.Sex == 0) & (train_2.Fare <= 10) & (train_2.Age < 35)].groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_2[(train_2.Sex == 1) & (train_2.Fare <= 10) & (train_2.Age < 35)].groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(16/21, 22/126, (22/126)/(16/21), (16/21)/(22/126))\n",
    "np.log((22/126)/(16/21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log((25/160)/(19/21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "females = train_2[(train_2.Sex == 1) & (train_2.Fare <= 10) & (train_2.Age < 35)].groupby('Survived').count()\n",
    "females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def odds(female, male):\n",
    "    female_surival = female.Sex[1] / female.Sex[0]\n",
    "\n",
    "females.Sex[1] / females.Sex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_2[(train_2.Sex == 0) & (train_2.Fare <= 10) & (train_2.Age < 35)].groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_2[(train_2.Sex == 0) & (train_2.Fare <= 11) & (train_2.Age < 35)].groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "23/137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "22/126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(22/126)/(23/137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_3 = LogisticRegression(C=1e10)\n",
    "\n",
    "train_age = train[(pd.notnull(train.Age))]\n",
    "clf_3.fit(train_age.Age.reshape(-1,1), train_age.Survived.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_3.intercept_, clf_3.coef_, np.exp(clf_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_age.Survived[train_age.Fare < 28].groupby(train_age.Survived).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "118/160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_age.Survived[train_age.Age < 29].groupby(train_age.Survived).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "124/177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(124/177)/(118/160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(148/216)/(118/160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "(clf_3.intercept_ + clf_3.coef_)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "train_age.plot(kind='scatter', x='Fare', y='Survived', ax=ax)\n",
    "\n",
    "ax.plot(np.linspace(train_age.Fare.min(), train_age.Age.max()),\n",
    "        [sigmoid((clf_3.intercept_ + clf_3.coef_*x)[0][0]) for x in np.linspace(train_age.Age.min(), train_age.Age.max())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### age factor for female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_4 = sklearn.linear_model.LogisticRegression(C=1e10)\n",
    "\n",
    "train_4 = train[features_4]\n",
    "features_4 = ['Sex', 'Age', 'Survived']\n",
    "#clf_4.fit(train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_4.fit(train[features_4].drop('Survived', axis=1), train[features_4].Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_4.intercept_, clf_4.coef_[0][0], clf_4.coef_[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,10))\n",
    "plt.scatter(train_4[train_4.Sex == 1].Age, train_4[train_4.Sex == 1].Survived)\n",
    "plt.plot(np.linspace(train_4[train_4.Sex == 1].Age.min(), train_4[train_4.Sex == 1].Age.max()),\n",
    "         [sigmoid(clf_4.intercept_[0] + clf_4.coef_[0][0] + clf_4.coef_[0][1]*x) \n",
    "             for x in np.linspace(train_4[train_4.Sex == 1].Age.min(), train_4[train_4.Sex == 1].Age.max())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(-50, 50)\n",
    "plt.plot(xx, sigmoid(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(new_train[features])\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(y_pred, new_train.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_pred, new_train.Survived))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklearn.preprocessing.scale(train[['Pclass', 'Sex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "\n",
    "title = \"Learning Curves (Naive Bayes)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = cross_validation.ShuffleSplit(digits.data.shape[0], n_iter=100,\n",
    "                                   test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = GaussianNB()\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = cross_validation.ShuffleSplit(digits.data.shape[0], n_iter=10,\n",
    "                                   test_size=0.2, random_state=0)\n",
    "estimator = SVC(gamma=0.001)\n",
    "plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Scrap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, figsize=(16,16))\n",
    "\n",
    "# Survival Count\n",
    "axes[0,0].set_title('Survival Count by Population')\n",
    "axes[0,0].set_ylabel('# Survived')\n",
    "axes[0,0].set_xlabel('Survived')\n",
    "population_survival_count = dataset.Survived.value_counts()\n",
    "population_survival_count.plot(kind='bar', ax=axes[0,0])\n",
    "\n",
    "axes[0,1].set_title('Survival Count for Females')\n",
    "axes[0,1].set_ylabel('# Survived')\n",
    "axes[0,1].set_xlabel('Survived')\n",
    "females_survival_count = dataset.Survived[dataset.Sex == 'female'].value_counts().sort_index(ascending=True)\n",
    "females_survival_count.plot(kind='bar', ax=axes[0,1])\n",
    "\n",
    "axes[0,2].set_title('Survival Count for Males')\n",
    "axes[0,2].set_ylabel('# Survived')\n",
    "axes[0,2].set_xlabel('Survived')\n",
    "male_surivival_count = dataset.Survived[dataset.Sex == 'male'].value_counts()\n",
    "male_surivival_count.plot(kind='bar', ax=axes[0,2])\n",
    "\n",
    "# Percent Survived\n",
    "axes[1,0].set_title('Survival Rate by Population')\n",
    "axes[1,0].set_ylabel('% Survived')\n",
    "axes[1,0].set_xlabel('Survived')\n",
    "(population_survival_count/population_survival_count.sum()).plot(kind='bar', ax=axes[1,0])\n",
    "\n",
    "axes[1,1].set_title('Survival Rate for Females')\n",
    "axes[1,1].set_ylabel('% Survived')\n",
    "axes[1,1].set_xlabel('Survived')\n",
    "(females_survival_count/females_survival_count.sum()).plot(kind='bar', ax=axes[1,1])\n",
    "\n",
    "axes[1,2].set_title('Survival Rate for Males')\n",
    "axes[1,2].set_ylabel('% Survived')\n",
    "axes[1,2].set_xlabel('Survived')\n",
    "(male_surivival_count/male_surivival_count.sum()).plot(kind='bar', ax=axes[1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plots out the count on the first row and the percentage breakdown on the second given some feature name\n",
    "def explore_features(features, dependent='Survived', df=dataset):\n",
    "    \n",
    "    # We got only 1 feature, let's plot the count and the ratio\n",
    "    if len(features) == 1:\n",
    "        feature = features[0]\n",
    "        unique_features = df[feature].dropna().unique()\n",
    "        columns = len(unique_features)\n",
    "\n",
    "        # Create figure and axes\n",
    "        fig, axes = plt.subplots(2, columns, figsize=(4*columns, 2*4))\n",
    "\n",
    "        for col, val in enumerate(np.sort(unique_features)):\n",
    "            feature_count = df[dependent][df[feature] == val].value_counts().sort_index(ascending=True)\n",
    "            axes[0, col].set_title('{} Count for {}={}'.format(dependent, feature, val))\n",
    "            axes[0, col].set_ylabel('# {}'.format(dependent)) if col == 0 else None\n",
    "            axes[0, col].set_xlabel(dependent)\n",
    "            feature_count.plot(kind='bar', ax=axes[0, col])\n",
    "\n",
    "            axes[1, col].set_title('{} Pct for {}={}'.format(dependent, feature, val))\n",
    "            axes[1, col].set_ylabel('% {}'.format(dependent)) if col == 0 else None\n",
    "            axes[1, col].set_xlabel(dependent)\n",
    "            (feature_count/feature_count.sum()).plot(kind='bar', ax=axes[1, col])\n",
    "    \n",
    "    # We got a list of 2 numbers, let's plot the surivival with the two features on x and y\n",
    "    elif len(features) == 2:\n",
    "        feature_x = features[0]\n",
    "        feature_y = features[1]\n",
    "        \n",
    "        unique_feature_x = df[feature_x].dropna().unique()\n",
    "        unique_feature_y = df[feature_y].dropna().unique()\n",
    "        \n",
    "        columns = len(unique_feature_x)\n",
    "        rows = len(unique_feature_y) \n",
    "        \n",
    "        fig, axes = plt.subplots(rows, columns, figsize=(4*columns, 4*rows))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explore_features(['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explore_features(['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore_features(['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
